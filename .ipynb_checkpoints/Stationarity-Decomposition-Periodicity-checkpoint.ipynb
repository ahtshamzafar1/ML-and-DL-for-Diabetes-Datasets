{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d70aa625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks, find_peaks_cwt\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9612eb",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6761214e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adf_test(time_series):\n",
    "    \"\"\"\n",
    "    param time_series: takes a time series list as an input\n",
    "    return: True/False as a results of KPSS alongside the output in dataframe\n",
    "    \"\"\"\n",
    "    dftest = adfuller(time_series, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4],\n",
    "                         index=[\n",
    "                             'Test Statistic', 'p-value', '#Lags Used',\n",
    "                             'Number of Observations Used'\n",
    "                         ])\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)' % key] = value\n",
    "\n",
    "    if dfoutput['p-value'] < 0.01:\n",
    "        return True, dfoutput\n",
    "    else:\n",
    "        return False, dfoutput\n",
    "\n",
    "\n",
    "def kpss_test(time_series):\n",
    "    kpsstest = kpss(time_series, regression='c')\n",
    "    dfoutput = pd.Series(kpsstest[0:3],\n",
    "                         index=['Test Statistic', 'p-value', 'Lags Used'])\n",
    "    for key, value in kpsstest[3].items():\n",
    "        dfoutput['Critical Value (%s)' % key] = value\n",
    "\n",
    "    if dfoutput['p-value'] < 0.01:\n",
    "        return False, dfoutput\n",
    "    else:\n",
    "        return True, dfoutput\n",
    "\n",
    "\n",
    "def most_frequent(list):\n",
    "    counter = 0\n",
    "    num = list[0]\n",
    "\n",
    "    for i in list:\n",
    "        curr_frequency = list.count(i)\n",
    "        if curr_frequency > counter:\n",
    "            counter = curr_frequency\n",
    "            num = i\n",
    "    return num\n",
    "\n",
    "\n",
    "def identify_cont_disc(df):\n",
    "    \"\"\"\n",
    "    :param df: the metric data column(s) that has no NAN or constant values\n",
    "    :return: list of continuous metrics and their corresponding data column(s)\n",
    "    \"\"\"\n",
    "    raw_feature_list = df.columns\n",
    "    raw_feature_list = list(raw_feature_list.values)\n",
    "\n",
    "    # feature_list = df.columns\n",
    "    discrete_features = []\n",
    "    continuous_features = []\n",
    "    for colum in raw_feature_list:\n",
    "        if len(df[colum].unique()) < 20:\n",
    "            # print(colum, ': ', df[colum].unique())\n",
    "            discrete_features.append(colum)\n",
    "        else:\n",
    "            # print(colum, \": continuous features\")\n",
    "            continuous_features.append(colum)\n",
    "    df_cont = df[continuous_features].copy()\n",
    "\n",
    "    df_disc = df[discrete_features].copy()\n",
    "\n",
    "    return continuous_features, discrete_features\n",
    "\n",
    "\n",
    "def analysisPeriod(df_raw, feature, time_feature, plot=False, verbose=False):\n",
    "    \"\"\"\n",
    "    :param df_raw: data set\n",
    "    :param feature: metric name\n",
    "    :param time_feature: time series name\n",
    "    :param plot: visual analysis functionality\n",
    "    :param verbose: print details on the console\n",
    "    :return: stationary, seasonal, period, decomposed series\n",
    "    \"\"\"\n",
    "\n",
    "    ## INITIALIZATION: time series should be normalised into [0, 1]\n",
    "\n",
    "    seasonal = False\n",
    "    stationary = False\n",
    "    df_ts = df_raw.copy()\n",
    "\n",
    "    # Stationary Check\n",
    "    # ADF TEST: Augmented Dickey–Fuller test\n",
    "    # KPSS TEST: Kwiatkowski–Phillips–Schmidt–Shin TEST\n",
    "    adf_result, adf_output = adf_test(df_ts[feature])\n",
    "    kpss_result, kpss_output = kpss_test(df_ts[feature])\n",
    "\n",
    "    if verbose:\n",
    "        print('adf-Test')\n",
    "        print(adf_result)\n",
    "        print(adf_output)\n",
    "        print('kpss-Test')\n",
    "        print(kpss_result)\n",
    "        print(kpss_output)\n",
    "\n",
    "    # This is the code to use two tests, it will return true for stationary if or(test1,test2) = True\n",
    "    if adf_result == True & kpss_result == True:\n",
    "        stationary = True\n",
    "    elif adf_result == True & kpss_result == False:\n",
    "        stationary = False\n",
    "        print(\"Difference Stationary\")\n",
    "    elif adf_result == False & kpss_result == True:\n",
    "        stationary = False\n",
    "        print(\"Trend Stationary\")\n",
    "    else:\n",
    "        stationary = False\n",
    "\n",
    "    # First: checking flat line.\n",
    "    if np.all(np.isclose(df_ts[feature].values, df_ts[feature].values[0])):\n",
    "        print('Constant series')\n",
    "        seasonal = False\n",
    "        period = 1\n",
    "        result_add = None\n",
    "    else:\n",
    "        # If not flat line then:\n",
    "        # Seasonality Check:\n",
    "\n",
    "        # Automatic find the period based on Time Index\n",
    "\n",
    "        # Shift windows to find autocorrelations\n",
    "        shift_ = []\n",
    "        for i in np.arange(len(df_ts[feature])):\n",
    "            shift_.append(df_ts[feature].autocorr(lag=i))\n",
    "        shift_ = np.array(shift_)\n",
    "\n",
    "        # if max of Autocorelation greater than 0.9, we have seasonal\n",
    "        if max(shift_) >= 0.9:\n",
    "            seasonal = True\n",
    "\n",
    "        # find peaks of autocorelation -> in order to find local maxima\n",
    "        # peaks, _ = find_peaks(shift_, height=0.5)\n",
    "        peaks = find_peaks_cwt(shift_, np.arange(1, 10))\n",
    "\n",
    "        # turn peaks into differences between peaks\n",
    "        diff = []\n",
    "        for i in np.arange(len(peaks) - 1):\n",
    "            diff.append(peaks[i + 1] - peaks[i])\n",
    "\n",
    "        if len(diff) == 0:  # can't find peaks\n",
    "            first_period = 1  # need to check again this!\n",
    "        else:\n",
    "            # return the most distance between peaks -> that is period of data\n",
    "            first_period = most_frequent(list(diff))\n",
    "\n",
    "        if verbose:\n",
    "            #print('Candidate periods:', set(diff))\n",
    "            for eachdiff in diff:\n",
    "                print(df_ts[feature].autocorr(lag=eachdiff), end='\\t')\n",
    "            print()\n",
    "\n",
    "        if (plot == True) & (verbose == True):\n",
    "            plt.figure(figsize=(20, 3))\n",
    "            sm.graphics.tsa.plot_acf(df_ts[feature].squeeze(),\n",
    "                                     lags=int(first_period))\n",
    "\n",
    "        # if period is too large\n",
    "        if first_period > int(len(df_ts) / 2):\n",
    "            if verbose:\n",
    "                print('Frequency for Moving Average is over half size!')\n",
    "            first_period = int(len(df_ts) / 2)\n",
    "\n",
    "        # SEASONAL ANALYSIS\n",
    "\n",
    "        if verbose:\n",
    "            print('First period:', first_period)\n",
    "\n",
    "        df_ts.index = pd.to_datetime(df_ts[time_feature],\n",
    "                                     format='%Y-%m-%d %H:%M:%S')\n",
    "        rolling_mean = df_ts[feature].rolling(window=int(first_period)).mean()\n",
    "        \n",
    "        exp1 = pd.Series(df_ts[feature].ewm(span=int(first_period),\n",
    "                                            adjust=False).mean())\n",
    "        \n",
    "        exp1.index = pd.to_datetime(df_ts[time_feature],\n",
    "                                    format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        if (verbose == True) & (plot == True):\n",
    "            df_ori = df_ts[[feature, time_feature]].copy()\n",
    "            df_ori.set_index(time_feature, inplace=True)\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(15, 4))\n",
    "\n",
    "            df_ori.plot(ax=ax)\n",
    "            exp1.plot(ax=ax)\n",
    "\n",
    "            ax.legend([\n",
    "                'Original Series',\n",
    "                'Moving Average Series with P=%d' % first_period\n",
    "            ])\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "        # Using Moving Average\n",
    "        result_add = seasonal_decompose(exp1,\n",
    "                                        model='additive',\n",
    "                                        extrapolate_trend='freq',\n",
    "                                        freq=first_period)\n",
    "\n",
    "        # Using STL\n",
    "        #         from statsmodels.tsa.seasonal import STL\n",
    "        #         stl = STL(exp1, period=first_period, robust=True)\n",
    "        #         result_add = stl.fit()\n",
    "\n",
    "        # Only check the seasonal series to find again the best period\n",
    "        arr_seasonal_ = pd.Series(result_add.seasonal + result_add.resid)\n",
    "\n",
    "        # if seasonal is flat\n",
    "        if np.all(np.isclose(arr_seasonal_, arr_seasonal_[0])):\n",
    "            if verbose == True:\n",
    "                print('Seasonal + Residual become flat')\n",
    "            seasonal = False\n",
    "            period = 1\n",
    "        else:\n",
    "            # if seasonal is not flat\n",
    "\n",
    "            # Continue to use autocorrelation to find the period\n",
    "            shift_ = []\n",
    "            for i in np.arange(len(arr_seasonal_)):\n",
    "                shift_.append(arr_seasonal_.autocorr(lag=i))\n",
    "\n",
    "            shift_ = np.array(shift_)\n",
    "\n",
    "            # Find peaks again for seasonal + residual\n",
    "            peaks, _ = find_peaks(shift_, height=0.85, distance=7)\n",
    "            #             peaks = find_peaks_cwt(shift_,np.arange(1,10))\n",
    "\n",
    "            # Looking for possible periods\n",
    "            if len(peaks) < 2:\n",
    "                if df_ts[feature].autocorr(lag=first_period) > 0.80:\n",
    "                    period = first_period\n",
    "                    seasonal = True\n",
    "                else:\n",
    "                    period = 1\n",
    "                    seasonal = False\n",
    "                    result_add = None\n",
    "            # result_add = seasonal_decompose(df_ts[feature], model='additive', extrapolate_trend='freq',freq=period)\n",
    "            else:\n",
    "                diff = []\n",
    "                for i in np.arange(len(peaks)):\n",
    "                    if i + 1 < len(peaks):\n",
    "                        diff.append(peaks[i + 1] - peaks[i])\n",
    "\n",
    "                if verbose:\n",
    "                    print('Candidate periods:', set(diff))\n",
    "                    for eachdiff in diff:\n",
    "                        print(df_ts[feature].autocorr(lag=eachdiff), end='\\t')\n",
    "                    print()\n",
    "\n",
    "                if verbose:\n",
    "                    print('Peaks of autocorr:', diff)\n",
    "                if 2 * most_frequent(list(diff)) > len(df_ts):\n",
    "                    seasonal = False\n",
    "                    period = 1\n",
    "                    result_add = None\n",
    "                else:\n",
    "                    seasonal = True\n",
    "                    period = most_frequent(list(diff))\n",
    "\n",
    "            if (plot == True) & (verbose == True):\n",
    "                sm.graphics.tsa.plot_acf(exp1.squeeze(), lags=int(period) * 2)\n",
    "                plt.show()\n",
    "\n",
    "            # Final Decomposition\n",
    "\n",
    "            result_add = seasonal_decompose(df_ts[feature],\n",
    "                                            model='additive',\n",
    "                                            extrapolate_trend='freq',\n",
    "                                            freq=period)\n",
    "\n",
    "            # plot results of decomposition\n",
    "            if plot:\n",
    "                plt.rcParams.update({'figure.figsize': (10, 10)})\n",
    "                result_add.plot()\n",
    "                plt.show()\n",
    "\n",
    "                plt.figure(figsize=(20, 3))\n",
    "                plt.plot(df_ts[feature].values, label=\"Timeseries\")\n",
    "                plt.axvline(x=0, color='r', ls='--')\n",
    "                plt.axvline(x=period, color='r', ls='--')\n",
    "                plt.grid(True)\n",
    "                plt.axis('tight')\n",
    "                plt.legend(loc=\"best\", fontsize=13)\n",
    "                plt.show()\n",
    "\n",
    "    continuous, discrete = identify_cont_disc(df_raw[[feature]])\n",
    "\n",
    "    return stationary, seasonal, period, result_add, continuous, discrete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eedc00c",
   "metadata": {},
   "source": [
    "## Timeseries Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfcfe5f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data is already tz-aware UTC, unable to set specified tz: Europe/Berlin",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7332/1467360415.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdf_weather\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Timestamp\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_weather\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Timestamp\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%Y-%m-%d %H:%M:%S'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdf_weather\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Timestamp\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDatetimeIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_weather\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Timestamp\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Europe/Berlin'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mTimestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_weather\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\datetimes.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, data, freq, tz, normalize, closed, ambiguous, dayfirst, yearfirst, dtype, copy, name)\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_extract_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m         dtarr = DatetimeArray._from_sequence_not_strict(\n\u001b[0m\u001b[0;32m    334\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py\u001b[0m in \u001b[0;36m_from_sequence_not_strict\u001b[1;34m(cls, data, dtype, copy, tz, freq, dayfirst, yearfirst, ambiguous)\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[0mfreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq_infer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_infer_freq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m         subarr, tz, inferred_freq = sequence_to_dt64ns(\n\u001b[0m\u001b[0;32m    356\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py\u001b[0m in \u001b[0;36msequence_to_dt64ns\u001b[1;34m(data, dtype, copy, tz, dayfirst, yearfirst, ambiguous, allow_object, allow_mixed, require_iso8601)\u001b[0m\n\u001b[0;32m   2082\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2083\u001b[0m         \u001b[1;31m# DatetimeArray -> ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2084\u001b[1;33m         \u001b[0mtz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_infer_tz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2085\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py\u001b[0m in \u001b[0;36m_maybe_infer_tz\u001b[1;34m(tz, inferred_tz)\u001b[0m\n\u001b[0;32m   2301\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2302\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtimezones\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtz_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minferred_tz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2303\u001b[1;33m         raise TypeError(\n\u001b[0m\u001b[0;32m   2304\u001b[0m             \u001b[1;34mf\"data is already tz-aware {inferred_tz}, unable to \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2305\u001b[0m             \u001b[1;34mf\"set specified tz: {tz}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: data is already tz-aware UTC, unable to set specified tz: Europe/Berlin"
     ]
    }
   ],
   "source": [
    "df_weather=pd.read_csv(r'C:\\Users\\ahtis\\OneDrive\\Desktop\\ARIMA\\data\\data.csv')\n",
    "df_weather = df_weather[1:60]\n",
    "df_weather = df_weather.dropna()\n",
    "\n",
    "feature_name = \"glucose\"  \n",
    "\n",
    "df_weather[\"Timestamp\"] = pd.to_datetime(df_weather[\"Timestamp\"], format='%Y-%m-%d %H:%M:%S', utc=True)\n",
    "df_weather[\"Timestamp\"] = pd.DatetimeIndex(df_weather[\"Timestamp\"], tz='Europe/Berlin')\n",
    "\n",
    "Timestamp = df_weather.columns[0]\n",
    "\n",
    "stationary, seasonal, period, resultdfs, continuous, discrete = analysisPeriod(\n",
    "    df_weather.head(2500),\n",
    "    feature=feature_name,\n",
    "    time_feature=Timestamp,\n",
    "    plot=True,\n",
    "    verbose=True)\n",
    "\n",
    "print(\"Timeseries %s is Stationary? %s \" % (feature_name, stationary))\n",
    "\n",
    "print(\"Timeseries %s is Seasonal? %s \" % (feature_name, seasonal))\n",
    "\n",
    "if seasonal and period > 1:\n",
    "    print(\"Period for Timeseries %s =  %s \" % (feature_name, period))\n",
    "if seasonal and period == 1:\n",
    "    print(\"Period for Timeseries %s is not found\" % (feature_name, period))\n",
    "\n",
    "if continuous:\n",
    "    print(\"Timeseries %s is Continuous\" % (feature_name))\n",
    "else:\n",
    "    print(\"Timeseries %s is Discrete\" % (feature_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7859c5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
